{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fine-tuning FunctionGemma with AutoTrain\n",
        "\n",
        "This notebook demonstrates how to fine-tune FunctionGemma using **AutoTrain Advanced** - a no-code solution from Hugging Face.\n",
        "\n",
        "**Objectives:**\n",
        "- Train the model to call `set_square_color` when the user wants to change the color\n",
        "- Train the model to call `get_square_color` when the user asks about the current color\n",
        "\n",
        "**Reference:** [AutoTrain Advanced](https://github.com/huggingface/autotrain-advanced)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q autotrain-advanced torch torchvision torchaudio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def format_function_call_output(tool_name: str, tool_arguments: dict) -> str:\n",
        "    if not tool_arguments:\n",
        "        return f\"<start_function_call>call:{tool_name}{{}}<end_function_call>\"\n",
        "    \n",
        "    args_parts = []\n",
        "    for key, value in tool_arguments.items():\n",
        "        if isinstance(value, str):\n",
        "            args_parts.append(f\"{key}:<escape>{value}<escape>\")\n",
        "        else:\n",
        "            args_parts.append(f\"{key}:{value}\")\n",
        "    \n",
        "    args_str = \",\".join(args_parts)\n",
        "    return f\"<start_function_call>call:{tool_name}{{{args_str}}}<end_function_call>\"\n",
        "\n",
        "with open(\"dataset/square_color_dataset.json\", \"r\") as f:\n",
        "    raw_data = json.load(f)\n",
        "\n",
        "autotrain_data = []\n",
        "for sample in raw_data:\n",
        "    tool_args = json.loads(sample[\"tool_arguments\"])\n",
        "    assistant_response = format_function_call_output(sample[\"tool_name\"], tool_args)\n",
        "    \n",
        "    autotrain_data.append({\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": sample[\"user_content\"]},\n",
        "            {\"role\": \"assistant\", \"content\": assistant_response}\n",
        "        ]\n",
        "    })\n",
        "\n",
        "with open(\"dataset/train.jsonl\", \"w\") as f:\n",
        "    for item in autotrain_data:\n",
        "        f.write(json.dumps(item) + \"\\n\")\n",
        "\n",
        "print(f\"Converted {len(autotrain_data)} examples to dataset/train.jsonl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = \"\"\"\n",
        "task: llm-sft\n",
        "base_model: google/functiongemma-270m-it\n",
        "project_name: functiongemma-square-color-autotrain\n",
        "log: tensorboard\n",
        "backend: local\n",
        "\n",
        "data:\n",
        "  path: dataset/\n",
        "  train_split: train\n",
        "  valid_split: null\n",
        "  chat_template: tokenizer\n",
        "  column_mapping:\n",
        "    text_column: messages\n",
        "\n",
        "params:\n",
        "  block_size: 512\n",
        "  model_max_length: 512\n",
        "  epochs: 8\n",
        "  batch_size: 4\n",
        "  lr: 5e-5\n",
        "  peft: false\n",
        "  quantization: null\n",
        "  padding: right\n",
        "  optimizer: adamw_torch\n",
        "  scheduler: constant\n",
        "  gradient_accumulation: 1\n",
        "  mixed_precision: bf16\n",
        "  merge_adapter: false\n",
        "\n",
        "hub:\n",
        "  username: [HF USERNAME]\n",
        "  token: [HF TOKEN]\n",
        "  push_to_hub: true\n",
        "\"\"\"\n",
        "\n",
        "with open(\"autotrain_config.yaml\", \"w\") as f:\n",
        "    f.write(config.strip())\n",
        "\n",
        "print(\"Created autotrain_config.yaml\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!autotrain --config autotrain_config.yaml\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
